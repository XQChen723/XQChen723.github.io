<!DOCTYPE html><html lang="zh-Hans"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="多元线性回归之模型选择"><meta name="keywords" content="统计学"><meta name="author" content="xqchen"><meta name="copyright" content="xqchen"><title>多元线性回归之模型选择 | ChenXQ の Blog</title><link rel="shortcut icon" href="/melody-favicon.ico"><link rel="stylesheet" href="/css/index.css?version=1.9.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css?version=1.9.0"><meta name="format-detection" content="telephone=no"><meta http-equiv="x-dns-prefetch-control" content="on"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  hexoVersion: '6.0.0'
} </script><meta name="generator" content="Hexo 6.0.0"></head><body><canvas class="fireworks"></canvas><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar" data-display="true"><div class="toggle-sidebar-info text-center"><span data-toggle="切换文章详情">切换站点概览</span><hr></div><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar"></div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%86%99%E5%9C%A8%E5%89%8D%E9%9D%A2"><span class="toc-number">1.</span> <span class="toc-text">写在前面</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A4%9A%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E4%BB%8B%E7%BB%8D"><span class="toc-number">2.</span> <span class="toc-text">多元线性回归介绍</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E7%94%A8%E4%B8%80%E4%BA%9B%E5%8F%AF%E4%BB%A3%E6%9B%BF%E7%9A%84%E6%8B%9F%E5%90%88%E6%96%B9%E6%B3%95%E4%BB%A3%E6%9B%BF%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95%E6%8B%9F%E5%90%88"><span class="toc-number">3.</span> <span class="toc-text">为什么要用一些可代替的拟合方法代替最小二乘法拟合</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8B%9F%E5%90%88%E7%B2%BE%E5%BA%A6"><span class="toc-number">3.1.</span> <span class="toc-text">拟合精度</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E8%A7%A3%E9%87%8A"><span class="toc-number">3.2.</span> <span class="toc-text">模型解释</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%AF%E6%9B%BF%E4%BB%A3%E7%9A%84%E6%96%B9%E6%B3%95"><span class="toc-number">4.</span> <span class="toc-text">可替代的方法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AD%90%E9%9B%86%E9%80%89%E6%8B%A9%EF%BC%88Subset-Selection%EF%BC%89"><span class="toc-number">4.1.</span> <span class="toc-text">子集选择（Subset Selection）</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#best-subset-selection"><span class="toc-number">4.1.1.</span> <span class="toc-text">best subset selection</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%80%90%E6%AD%A5%E5%9B%9E%E5%BD%92"><span class="toc-number">4.1.2.</span> <span class="toc-text">逐步回归</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9C%80%E4%BC%98%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%80%89%E6%8B%A9"><span class="toc-number">4.1.3.</span> <span class="toc-text">最优模型的选择</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%BB%83%E4%B9%A0"><span class="toc-number">4.1.4.</span> <span class="toc-text">练习</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#Subset-Selection"><span class="toc-number">4.1.4.1.</span> <span class="toc-text">Subset Selection</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#3-1-4-2-Forward-and-Backward-Stepwise"><span class="toc-number">4.1.4.2.</span> <span class="toc-text">3.1.4.2 Forward and Backward Stepwise</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Choose-the-best-model-using-the-validation-set"><span class="toc-number">4.1.4.3.</span> <span class="toc-text">Choose the best model:using the validation set</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#choose-the-best-model-using-cross-validation"><span class="toc-number">4.1.4.4.</span> <span class="toc-text">choose the best model:using cross-validation</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%89%B9%E5%BE%81%E7%BC%A9%E5%87%8F%EF%BC%88Shrinkage%EF%BC%89"><span class="toc-number">4.2.</span> <span class="toc-text">特征缩减（Shrinkage）</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Lasso%E5%9B%9E%E5%BD%92"><span class="toc-number">4.2.1.</span> <span class="toc-text">Lasso回归</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Ridge%E5%9B%9E%E5%BD%92"><span class="toc-number">4.2.2.</span> <span class="toc-text">Ridge回归</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%BB%83%E4%B9%A0-1"><span class="toc-number">4.2.3.</span> <span class="toc-text">练习</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Dimension-Reduction"><span class="toc-number">4.3.</span> <span class="toc-text">Dimension Reduction</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Principal-Components-Regression-Approach"><span class="toc-number">4.3.1.</span> <span class="toc-text">Principal Components Regression Approach</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Partial-Least-Squares"><span class="toc-number">4.3.2.</span> <span class="toc-text">Partial Least Squares</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%BB%83%E4%B9%A0-2"><span class="toc-number">4.3.3.</span> <span class="toc-text">练习</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99"><span class="toc-number">5.</span> <span class="toc-text">参考资料</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#YouTube%E8%A7%86%E9%A2%91"><span class="toc-number">5.1.</span> <span class="toc-text">YouTube视频</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BD%91%E7%AB%99"><span class="toc-number">5.2.</span> <span class="toc-text">网站</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B9%A6%E7%B1%8D"><span class="toc-number">5.3.</span> <span class="toc-text">** 书籍**</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BB%83%E4%B9%A0%E6%95%B0%E6%8D%AE"><span class="toc-number">5.4.</span> <span class="toc-text">练习数据</span></a></li></ol></li></ol></div></div><div class="author-info hide"><div class="author-info__avatar text-center"><img src="https://pic1.zhimg.com/v2-f755f16a86f3e21626de19348b4f4a8d_r.jpg?source=1940ef5c"></div><div class="author-info__name text-center">xqchen</div><div class="author-info__description text-center">Study Notes</div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">文章</span><span class="pull-right">2</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">标签</span><span class="pull-right">2</span></a><a class="author-info-articles__categories article-meta" href="/categories"><span class="pull-left">分类</span><span class="pull-right">2</span></a></div></div></div><div id="content-outer"><div id="top-container" style="background-image: url(https://cdn.pixabay.com/photo/2022/03/01/11/26/the-bedouins-7041111_1280.jpg)"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">ChenXQ の Blog</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus">   <a class="site-page" href="/">主页</a><a class="site-page" href="/archives">归档</a><a class="site-page" href="/tags">标签</a><a class="site-page" href="/categories">分类</a></span><span class="pull-right"></span></div><div id="post-info"><div id="post-title">多元线性回归之模型选择</div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2022-03-04</time><span class="post-meta__separator">|</span><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/%E5%A4%9A%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E4%B9%8B%E6%A8%A1%E5%9E%8B%E9%80%89%E6%8B%A9/">多元线性回归之模型选择</a></div></div></div><div class="layout" id="content-inner"><article id="post"><div class="article-container" id="post-content"><h2 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h2><ul>
<li><p><strong>目的：对需要分析的数据集进行模型选择，帮助理解多元线性回归以及对实验结果进行更好分析</strong></p>
</li>
<li><p><strong>其中包括多元线性回归中特征的选择、特征缩减以及对特征进行降维等；附上实现以上过程的代码与部分注释，数据集位于’E:&#x2F;finaldata&#x2F;Rst&#x2F;final_data_2.csv’</strong></p>
</li>
<li><p><strong>该笔记对原理基于自己的理解，相对简洁。后续可详见《An Introduction to Statistical Learning with Applications in R》</strong></p>
</li>
<li><p>**学于20220228-20220302 **</p>
</li>
</ul>
<hr>
<h2 id="多元线性回归介绍"><a href="#多元线性回归介绍" class="headerlink" title="多元线性回归介绍"></a>多元线性回归介绍</h2><p>在回归分析中，如果有两个或两个以上的<a href="https://link.zhihu.com/?target=https://baike.baidu.com/item/%E8%87%AA%E5%8F%98%E9%87%8F/6895256">自变量</a>，就称为多元回归。实际应用中，一种现象常常是与多个因素相联系的，由多个自变量的最优组合共同来<a href="https://link.zhihu.com/?target=https://baike.baidu.com/item/%E9%A2%84%E6%B5%8B/35966">预测</a>或<a href="https://link.zhihu.com/?target=https://baike.baidu.com/item/%E4%BC%B0%E8%AE%A1/8678215">估计</a><a href="https://link.zhihu.com/?target=https://baike.baidu.com/item/%E5%9B%A0%E5%8F%98%E9%87%8F/5872908">因变量</a>，比只用一个自变量进行预测或估计更有效，更符合实际。总的来说，回归分析就是用来做预测的，多元回归要比一元回归更加高效实用。</p>
<p><img src="https://pic3.zhimg.com/80/v2-faf12d07ccc774196e619a701e85bfd6_720w.jpg" alt="img"></p>
<p>如果线性回归方程存在，那么我们要求出每一项 X 前的系数 <img src="https://www.zhihu.com/equation?tex=b+_%7Bi%7D" alt="[公式]"> 和常数项 <img src="https://www.zhihu.com/equation?tex=b_%7B0%7D" alt="[公式]"> 。若要使求得的回归方程效果比较好，也就是使预测值(估计值)与样本值 Y 最接近。让误差平方和 Q 最小，使用最小二乘法，避免了正负抵消问题。那么使回归模型最有效问题转化为求 Q 的最小值问题。</p>
<p><img src="https://pic2.zhimg.com/80/v2-79218904c3b7a1e096c009c1a1af607d_720w.jpg" alt="img"></p>
<h2 id="为什么要用一些可代替的拟合方法代替最小二乘法拟合"><a href="#为什么要用一些可代替的拟合方法代替最小二乘法拟合" class="headerlink" title="为什么要用一些可代替的拟合方法代替最小二乘法拟合"></a>为什么要用一些可代替的拟合方法代替最小二乘法拟合</h2><h3 id="拟合精度"><a href="#拟合精度" class="headerlink" title="拟合精度"></a>拟合精度</h3><ul>
<li>如果样本量远大于模型中的自变量的数量，使用最小二乘法会有较低的方差，拟合模型的预测精度也会更好</li>
<li>但如果样本小于自变量的数量，就不再有最小二乘系数的估计：即方差是无穷的。因此该方法不能使用。</li>
</ul>
<h3 id="模型解释"><a href="#模型解释" class="headerlink" title="模型解释"></a>模型解释</h3><ul>
<li>多元线性回归模型中的许多自变量X常与因变量Y无关，将这些不相关的自变量带入模型会导致最终模型不必要的复杂性。</li>
<li>移除这些无关的自变量（使得相应的系数为0）可以让最终的模型更有解释性，但最小二乘法不怎么可能产生接近0的系数。</li>
</ul>
<h2 id="可替代的方法"><a href="#可替代的方法" class="headerlink" title="可替代的方法"></a>可替代的方法</h2><p>定义有p个自变量，n个样本量</p>
<h3 id="子集选择（Subset-Selection）"><a href="#子集选择（Subset-Selection）" class="headerlink" title="子集选择（Subset Selection）"></a>子集选择（Subset Selection）</h3><h4 id="best-subset-selection"><a href="#best-subset-selection" class="headerlink" title="best subset selection"></a>best subset selection</h4><p><strong>定义</strong>：对p进行组合，得到每种组合的最小二乘回归。一共有2^p个模型</p>
<p><strong>算法：</strong></p>
<ul>
<li><p>定义一个包含0个自变量的空模型M0；</p>
</li>
<li><p>对于k&#x3D;1，2，3……p:</p>
<p>(a)拟合<img src="file:///C:/Users/CHEXIA~1/AppData/Local/Temp/msohtmlclip1/01/clip_image002.png" alt="img">个模型，这些模型包含k个自变量</p>
<p>(b)通过最小的RSS或者最大的R方来选择以上最好的模型Mk</p>
</li>
<li><p>使用交叉验证、AIC、BIC或者调整R方的方法，在M0、M1……Mk中选择一个最好的模型</p>
</li>
</ul>
<p><strong>注意：</strong>在算法的（b）中，<strong>随着k的增加，RSS会单调减少，R方会单调增加</strong>。所以必须要再进行一步：使用交叉验证、AIC等</p>
<p><strong>优点</strong>：简单，易于理解</p>
<p><strong>不足：</strong>计算量。如果p&#x3D;40，计算机要执行2^40次运算。</p>
<h4 id="逐步回归"><a href="#逐步回归" class="headerlink" title="逐步回归"></a>逐步回归</h4><ul>
<li><strong>向前逐步回归</strong></li>
</ul>
<p><strong>定义：</strong>从一个不包含自变量的模型M0开始，一次添加一个自变量X，直达所有的X都在模型中。一共有<img src="file:///C:/Users/CHEXIA~1/AppData/Local/Temp/msohtmlclip1/01/clip_image002.png" alt="img">个模型。</p>
<p><strong>优点：</strong>对比best subset selection有计算上的优势（模型大大减少）</p>
<p><strong>缺点：</strong>得到的模型并不一定是最好的。比如有一个数据集有三个自变量，包含一个变量的最好模型是X1，但包含两个自变量的最好模型是X2和X3。但通过向前逐步回归，不会选择出最好的两个变量模型，因为其必须包含X1。</p>
<ul>
<li><strong>向后逐步回归</strong></li>
</ul>
<p><strong>定义：</strong>从包含所有自变量的模型M0开始。</p>
<p>其余与向前逐步回归类似。</p>
<h4 id="最优模型的选择"><a href="#最优模型的选择" class="headerlink" title="最优模型的选择"></a>最优模型的选择</h4><p><strong>方法：</strong></p>
<ul>
<li>通过对训练误差进行调整来考虑过拟合造成的偏差来简介估计测试误差，通过指标：<ul>
<li>Cp：越小模型越好</li>
<li>AIC（赤池信息量 akaike information criterion）：越小模型越好;对于最小二乘模型，AIC与Cp成比例，做出来的图也应该是一样的</li>
<li>BIC(贝叶斯信息量 bayesian information criterion)：越小模型越好</li>
<li>调整后R方：越大模型越好</li>
<li>AIC与BIC的区别：BIC的惩罚项比AIC的大，考虑了样本数量，样本数量过多时，可有效防止模型精度过高造成的模型复杂度过高。AIC和BIC的原理是不同的，AIC是从预测角度，选择一个好的模型用来预测，BIC是从拟合角度，选择一个对现有数据拟合最好的模型，从贝叶斯因子的解释来讲，就是边际似然最大的那个模型。由于BIC惩罚越大，最后得到的模型应该是包含更少的自变量</li>
</ul>
</li>
<li><strong>使用验证集或者交叉验证</strong></li>
</ul>
<h4 id="练习"><a href="#练习" class="headerlink" title="练习"></a>练习</h4><p>该数据集有549个观测值，32个变量，其中1个因变量Y为popA，有31个自变量，即X1……X31。</p>
<h5 id="Subset-Selection"><a href="#Subset-Selection" class="headerlink" title="Subset Selection"></a>Subset Selection</h5><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">######  report the best model ########</span></span><br><span class="line"><span class="comment">#默认是输出八个参数的最好模型</span></span><br><span class="line">library<span class="punctuation">(</span>leaps<span class="punctuation">)</span></span><br><span class="line">regfit.full<span class="operator">=</span>regsubsets<span class="punctuation">(</span>popA<span class="operator">~</span>.<span class="punctuation">,</span>infsel<span class="punctuation">)</span></span><br><span class="line">summary<span class="punctuation">(</span>regfit.full<span class="punctuation">)</span> </span><br><span class="line"><span class="comment">#可以在regsubsets()添加参数nvmax，返回所想要变量数目的模型</span></span><br><span class="line">regfit.full<span class="operator">=</span>regsubsets<span class="punctuation">(</span>popA<span class="operator">~</span>.<span class="punctuation">,</span>infsel<span class="punctuation">,</span>nvmax<span class="operator">=</span><span class="number">31</span><span class="punctuation">)</span></span><br><span class="line">reg.summary<span class="operator">=</span>summary<span class="punctuation">(</span>regfit.full<span class="punctuation">)</span> </span><br><span class="line"><span class="comment">#其中summary()包含BIC、AIC等,可以帮助我们选择最好的模型</span></span><br><span class="line"><span class="built_in">names</span><span class="punctuation">(</span>reg.summary<span class="punctuation">)</span></span><br><span class="line"><span class="comment">#通过画图进行判别，选择最好的参数数量</span></span><br><span class="line">par<span class="punctuation">(</span>mfrow<span class="operator">=</span><span class="built_in">c</span><span class="punctuation">(</span><span class="number">2</span><span class="punctuation">,</span><span class="number">2</span><span class="punctuation">)</span><span class="punctuation">)</span></span><br><span class="line">plot<span class="punctuation">(</span>reg.summary<span class="operator">$</span>rss<span class="punctuation">,</span>xlab <span class="operator">=</span> <span class="string">&#x27;Number of Variables&#x27;</span><span class="punctuation">,</span></span><br><span class="line">     ylab <span class="operator">=</span> <span class="string">&quot;RSS&quot;</span><span class="punctuation">,</span>type <span class="operator">=</span> <span class="string">&quot;l&quot;</span><span class="punctuation">)</span></span><br><span class="line"><span class="comment">## plot adjr2 ##</span></span><br><span class="line">plot<span class="punctuation">(</span>reg.summary<span class="operator">$</span>adjr2<span class="punctuation">,</span>xlab <span class="operator">=</span> <span class="string">&#x27;Number of Variables&#x27;</span><span class="punctuation">,</span></span><br><span class="line">     ylab <span class="operator">=</span> <span class="string">&quot;Adjusted RSq&quot;</span><span class="punctuation">,</span>type <span class="operator">=</span> <span class="string">&quot;l&quot;</span><span class="punctuation">)</span></span><br><span class="line">which.max<span class="punctuation">(</span>reg.summary<span class="operator">$</span>adjr2<span class="punctuation">)</span></span><br><span class="line">points<span class="punctuation">(</span><span class="number">19</span><span class="punctuation">,</span>reg.summary<span class="operator">$</span>adjr2<span class="punctuation">[</span><span class="number">19</span><span class="punctuation">]</span><span class="punctuation">,</span>col<span class="operator">=</span><span class="string">&#x27;red&#x27;</span><span class="punctuation">,</span>cex<span class="operator">=</span><span class="number">2</span><span class="punctuation">,</span>pch<span class="operator">=</span><span class="number">20</span><span class="punctuation">)</span></span><br><span class="line"><span class="comment">## plot cp ##</span></span><br><span class="line">plot<span class="punctuation">(</span>reg.summary<span class="operator">$</span>cp<span class="punctuation">,</span>xlab <span class="operator">=</span> <span class="string">&#x27;Number of Variables&#x27;</span><span class="punctuation">,</span></span><br><span class="line">     ylab <span class="operator">=</span> <span class="string">&quot;cp&quot;</span><span class="punctuation">,</span>type <span class="operator">=</span> <span class="string">&quot;l&quot;</span><span class="punctuation">)</span></span><br><span class="line">which.min<span class="punctuation">(</span>reg.summary<span class="operator">$</span>cp<span class="punctuation">)</span></span><br><span class="line">points<span class="punctuation">(</span><span class="number">15</span><span class="punctuation">,</span>reg.summary<span class="operator">$</span>cp<span class="punctuation">[</span><span class="number">15</span><span class="punctuation">]</span><span class="punctuation">,</span>col<span class="operator">=</span><span class="string">&#x27;red&#x27;</span><span class="punctuation">,</span>cex<span class="operator">=</span><span class="number">2</span><span class="punctuation">,</span>pch<span class="operator">=</span><span class="number">20</span><span class="punctuation">)</span></span><br><span class="line"><span class="comment">## plot bic ##</span></span><br><span class="line">plot<span class="punctuation">(</span>reg.summary<span class="operator">$</span>bic<span class="punctuation">,</span>xlab <span class="operator">=</span> <span class="string">&#x27;Number of Variables&#x27;</span><span class="punctuation">,</span></span><br><span class="line">     ylab <span class="operator">=</span> <span class="string">&quot;bic&quot;</span><span class="punctuation">,</span>type <span class="operator">=</span> <span class="string">&quot;l&quot;</span><span class="punctuation">)</span></span><br><span class="line">which.min<span class="punctuation">(</span>reg.summary<span class="operator">$</span>bic<span class="punctuation">)</span></span><br><span class="line">points<span class="punctuation">(</span><span class="number">11</span><span class="punctuation">,</span>reg.summary<span class="operator">$</span>bic<span class="punctuation">[</span><span class="number">11</span><span class="punctuation">]</span><span class="punctuation">,</span>col<span class="operator">=</span><span class="string">&#x27;red&#x27;</span><span class="punctuation">,</span>cex<span class="operator">=</span><span class="number">2</span><span class="punctuation">,</span>pch<span class="operator">=</span><span class="number">20</span><span class="punctuation">)</span></span><br></pre></td></tr></table></figure>

<p>得到的图如下：</p>
<p><img src="/2022/03/04/%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B%E9%80%89%E6%8B%A9/image-20220302133906303.png" alt="image-20220302133906303"></p>
<p>通过best subset selection：依据调整后的R方选择的最优自变量数是19，依据Cp是15，依据BIC是11。（注意不适合用RSS来说明，见上方理论描述）</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## use bulit-in plot()command ##</span></span><br><span class="line"><span class="comment">#选择每个图形最上面一行填满黑块的个数为最优模型的变量个数</span></span><br><span class="line">plot<span class="punctuation">(</span>regfit.full<span class="punctuation">,</span>scale <span class="operator">=</span> <span class="string">&quot;r2&quot;</span><span class="punctuation">)</span></span><br><span class="line">plot<span class="punctuation">(</span>regfit.full<span class="punctuation">,</span>scale <span class="operator">=</span> <span class="string">&quot;adjr2&quot;</span><span class="punctuation">)</span></span><br><span class="line">plot<span class="punctuation">(</span>regfit.full<span class="punctuation">,</span>scale <span class="operator">=</span> <span class="string">&quot;Cp&quot;</span><span class="punctuation">)</span></span><br><span class="line">plot<span class="punctuation">(</span>regfit.full<span class="punctuation">,</span>scale <span class="operator">=</span> <span class="string">&quot;bic&quot;</span><span class="punctuation">)</span></span><br></pre></td></tr></table></figure>

<p>结果图如下：由图可以看出由adjr2选择来的最优变量数为19，以此类推。该结果与上面用which.min()求出来的一致</p>
<p><img src="/2022/03/04/%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B%E9%80%89%E6%8B%A9/image-20220302134908644.png" alt="image-20220302134908644"></p>
 <figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#根据adjr2的结果来拟合模型的系数</span></span><br><span class="line">coef<span class="punctuation">(</span>regfit.full<span class="punctuation">,</span><span class="number">19</span><span class="punctuation">)</span></span><br></pre></td></tr></table></figure>



<h5 id="3-1-4-2-Forward-and-Backward-Stepwise"><a href="#3-1-4-2-Forward-and-Backward-Stepwise" class="headerlink" title="3.1.4.2 Forward and Backward Stepwise"></a>3.1.4.2 Forward and Backward Stepwise</h5><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">###### regsubsets():Forward and Backward Stepwise Selection #######</span></span><br><span class="line"><span class="comment"># 执行逐步回归，只要在上面的基础上加上method=&#x27;&#x27; #</span></span><br><span class="line">regfit.fwd<span class="operator">=</span>regsubsets<span class="punctuation">(</span>popA<span class="operator">~</span>.<span class="punctuation">,</span>data <span class="operator">=</span> infsel<span class="punctuation">,</span>nvmax <span class="operator">=</span> <span class="number">31</span><span class="punctuation">,</span>method <span class="operator">=</span> <span class="string">&#x27;forward&#x27;</span><span class="punctuation">)</span></span><br><span class="line">summary<span class="punctuation">(</span>regfit.fwd<span class="punctuation">)</span></span><br><span class="line">regfit.bwd<span class="operator">=</span>regsubsets<span class="punctuation">(</span>popA<span class="operator">~</span>.<span class="punctuation">,</span>data <span class="operator">=</span> infsel<span class="punctuation">,</span>nvmax <span class="operator">=</span> <span class="number">31</span><span class="punctuation">,</span>method <span class="operator">=</span> <span class="string">&#x27;backward&#x27;</span><span class="punctuation">)</span></span><br><span class="line">summary<span class="punctuation">(</span>regfit.bwd<span class="punctuation">)</span></span><br></pre></td></tr></table></figure>

<h5 id="Choose-the-best-model-using-the-validation-set"><a href="#Choose-the-best-model-using-the-validation-set" class="headerlink" title="Choose the best model:using the validation set"></a>Choose the best model:using the validation set</h5><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">###### choose the best model:using the validation set #######</span></span><br><span class="line"><span class="comment">#设定种子，为了让代码重跑时候，模拟能重复出现</span></span><br><span class="line">set.seed<span class="punctuation">(</span><span class="number">1</span><span class="punctuation">)</span></span><br><span class="line"><span class="comment">#随机抽样，在向量c(TRUE,FALSE)重复抽取nrow(infsel)次</span></span><br><span class="line"><span class="comment">#抽样结果为true值则为训练集</span></span><br><span class="line">train<span class="operator">=</span>sample<span class="punctuation">(</span><span class="built_in">c</span><span class="punctuation">(</span><span class="literal">TRUE</span><span class="punctuation">,</span><span class="literal">FALSE</span><span class="punctuation">)</span><span class="punctuation">,</span>nrow<span class="punctuation">(</span>infsel<span class="punctuation">)</span><span class="punctuation">,</span></span><br><span class="line">             replace <span class="operator">=</span> <span class="literal">TRUE</span><span class="punctuation">)</span></span><br><span class="line"><span class="comment">#抽样结果为true值则为测试集</span></span><br><span class="line">test<span class="operator">=</span><span class="punctuation">(</span><span class="operator">!</span>train<span class="punctuation">)</span></span><br><span class="line">regfit.best<span class="operator">=</span>regsubsets<span class="punctuation">(</span>popA<span class="operator">~</span>.<span class="punctuation">,</span>data <span class="operator">=</span> infsel<span class="punctuation">[</span>train<span class="punctuation">,</span><span class="punctuation">]</span><span class="punctuation">,</span>nvmax <span class="operator">=</span> <span class="number">31</span><span class="punctuation">)</span></span><br><span class="line">summary<span class="punctuation">(</span>regfit.best<span class="punctuation">)</span></span><br><span class="line"><span class="comment"># plot 画图判别最优变量数</span></span><br><span class="line">plot<span class="punctuation">(</span>regfit.best<span class="punctuation">,</span>scale <span class="operator">=</span> <span class="string">&quot;r2&quot;</span><span class="punctuation">)</span></span><br><span class="line">plot<span class="punctuation">(</span>regfit.best<span class="punctuation">,</span>scale <span class="operator">=</span> <span class="string">&quot;adjr2&quot;</span><span class="punctuation">)</span></span><br><span class="line">plot<span class="punctuation">(</span>regfit.best<span class="punctuation">,</span>scale <span class="operator">=</span> <span class="string">&quot;Cp&quot;</span><span class="punctuation">)</span></span><br><span class="line">plot<span class="punctuation">(</span>regfit.best<span class="punctuation">,</span>scale <span class="operator">=</span> <span class="string">&quot;bic&quot;</span><span class="punctuation">)</span></span><br><span class="line"><span class="comment">#building an &#x27;X&#x27; matrix</span></span><br><span class="line">test.mat<span class="operator">=</span>model.matrix<span class="punctuation">(</span>popA<span class="operator">~</span>.<span class="punctuation">,</span>data <span class="operator">=</span> infsel<span class="punctuation">[</span>test<span class="punctuation">,</span><span class="punctuation">]</span><span class="punctuation">)</span></span><br><span class="line"><span class="comment">#run a loop to compute the test MSE</span></span><br><span class="line"><span class="comment">#首先创建一个空向量</span></span><br><span class="line">val.errors<span class="operator">=</span><span class="built_in">rep</span><span class="punctuation">(</span><span class="literal">NA</span><span class="punctuation">,</span><span class="number">31</span><span class="punctuation">)</span></span><br><span class="line"><span class="comment">#i代表自变量数，从1开始循环</span></span><br><span class="line"><span class="keyword">for</span> <span class="punctuation">(</span>i <span class="keyword">in</span> <span class="number">1</span><span class="operator">:</span><span class="number">31</span><span class="punctuation">)</span> <span class="punctuation">&#123;</span></span><br><span class="line">  coefi<span class="operator">=</span>coef<span class="punctuation">(</span>regfit.best<span class="punctuation">,</span>id<span class="operator">=</span>i<span class="punctuation">)</span></span><br><span class="line">  pred<span class="operator">=</span>test.mat<span class="punctuation">[</span><span class="punctuation">,</span><span class="built_in">names</span><span class="punctuation">(</span>coefi<span class="punctuation">)</span><span class="punctuation">]</span><span class="operator">%*%</span>coefi</span><br><span class="line">  val.errors<span class="punctuation">[</span>i<span class="punctuation">]</span><span class="operator">=</span>mean<span class="punctuation">(</span><span class="punctuation">(</span>infsel<span class="operator">$</span>popA<span class="punctuation">[</span>test<span class="punctuation">]</span><span class="operator">-</span>pred<span class="punctuation">)</span><span class="operator">^</span><span class="number">2</span><span class="punctuation">)</span></span><br><span class="line">  </span><br><span class="line"><span class="punctuation">&#125;</span></span><br><span class="line">val.errors</span><br><span class="line"><span class="comment"># find the lowest errors</span></span><br><span class="line">which.min<span class="punctuation">(</span>val.errors<span class="punctuation">)</span> <span class="comment">#15</span></span><br><span class="line">coef<span class="punctuation">(</span>regfit.best<span class="punctuation">,</span><span class="number">15</span><span class="punctuation">)</span></span><br><span class="line"><span class="comment">#the former is the best fifth-variable model,the next is full data set</span></span><br><span class="line"><span class="comment">#前面是通过训练集得到15个变量是最优模型，但整个数据集最好的15个可能不等同于训练集的15个，因此还需对全数据集进行最优子集选取，选出最优的15变量模型</span></span><br><span class="line">regfit.best<span class="operator">=</span>regsubsets<span class="punctuation">(</span>popA<span class="operator">~</span>.<span class="punctuation">,</span>data <span class="operator">=</span> infsel<span class="punctuation">,</span>nvmax <span class="operator">=</span> <span class="number">31</span><span class="punctuation">)</span></span><br><span class="line">coef<span class="punctuation">(</span>regfit.best<span class="punctuation">,</span><span class="number">15</span><span class="punctuation">)</span></span><br><span class="line"><span class="comment"># 查看拟合情况</span></span><br><span class="line">LMTEST<span class="operator">=</span>lm<span class="punctuation">(</span>popA<span class="operator">~</span>S.P<span class="operator">+</span>AI<span class="operator">+</span>ELEV<span class="operator">+</span>SDP<span class="operator">+</span>SDT<span class="operator">+</span>SC<span class="operator">+</span>SAF<span class="operator">+</span>CLF<span class="operator">+</span>por..rock<span class="operator">+</span>per..rock<span class="operator">+</span>MaxLAI<span class="operator">+</span>diffLAI<span class="operator">+</span>diffGVF<span class="operator">+</span>RD50<span class="operator">+</span>RD90<span class="punctuation">,</span>data <span class="operator">=</span> infsel<span class="punctuation">)</span></span><br><span class="line">summary<span class="punctuation">(</span>LMTEST<span class="punctuation">)</span></span><br></pre></td></tr></table></figure>

<p>coef(regfit.best,15)的结果：</p>
<p><img src="/2022/03/04/%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B%E9%80%89%E6%8B%A9/image-20220302162114013.png" alt="image-20220302162114013"></p>
<p><strong>模型拟合结果：</strong></p>
<p>（可以看出均满足显著性检验）</p>
<p><img src="/2022/03/04/%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B%E9%80%89%E6%8B%A9/image-20220302162233257.png" alt="image-20220302162233257"></p>
<h5 id="choose-the-best-model-using-cross-validation"><a href="#choose-the-best-model-using-cross-validation" class="headerlink" title="choose the best model:using cross-validation"></a>choose the best model:using cross-validation</h5><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">###### choose the best model:using cross-validation #######</span></span><br><span class="line">k<span class="operator">=</span><span class="number">15</span></span><br><span class="line">n<span class="operator">=</span>nrow<span class="punctuation">(</span>infsel<span class="punctuation">)</span></span><br><span class="line">set.seed<span class="punctuation">(</span><span class="number">1</span><span class="punctuation">)</span></span><br><span class="line">folds<span class="operator">=</span>sample<span class="punctuation">(</span><span class="built_in">rep</span><span class="punctuation">(</span><span class="number">1</span><span class="operator">:</span>k<span class="punctuation">,</span><span class="built_in">length</span><span class="operator">=</span>n<span class="punctuation">)</span><span class="punctuation">)</span></span><br><span class="line"><span class="comment">#创建一个k行31列的矩阵来存放结果</span></span><br><span class="line">cv.error<span class="operator">=</span>matrix<span class="punctuation">(</span><span class="literal">NA</span><span class="punctuation">,</span>k<span class="punctuation">,</span><span class="number">31</span><span class="punctuation">,</span></span><br><span class="line">                <span class="built_in">dimnames</span> <span class="operator">=</span> <span class="built_in">list</span><span class="punctuation">(</span><span class="literal">NULL</span><span class="punctuation">,</span>paste<span class="punctuation">(</span><span class="number">1</span><span class="operator">:</span><span class="number">31</span><span class="punctuation">)</span><span class="punctuation">)</span><span class="punctuation">)</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line">predict.regsubsets<span class="operator">=</span><span class="keyword">function</span><span class="punctuation">(</span>object<span class="punctuation">,</span>newdata<span class="punctuation">,</span>id<span class="punctuation">,</span>...<span class="punctuation">)</span><span class="punctuation">&#123;</span></span><br><span class="line">  form<span class="operator">=</span>as.formula<span class="punctuation">(</span>object<span class="operator">$</span><span class="built_in">call</span><span class="punctuation">[[</span><span class="number">2</span><span class="punctuation">]</span><span class="punctuation">]</span><span class="punctuation">)</span></span><br><span class="line">  mat<span class="operator">=</span>model.matrix<span class="punctuation">(</span>form<span class="punctuation">,</span>newdata<span class="punctuation">)</span></span><br><span class="line">  coefi<span class="operator">=</span>coef<span class="punctuation">(</span>object<span class="punctuation">,</span>id<span class="operator">=</span>id<span class="punctuation">)</span></span><br><span class="line">  xvars<span class="operator">=</span><span class="built_in">names</span><span class="punctuation">(</span>coefi<span class="punctuation">)</span></span><br><span class="line">  mat<span class="punctuation">[</span><span class="punctuation">,</span>xvars<span class="punctuation">]</span><span class="operator">%*%</span>coefi</span><br><span class="line"><span class="punctuation">&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> <span class="punctuation">(</span>j <span class="keyword">in</span> <span class="number">1</span><span class="operator">:</span>k<span class="punctuation">)</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="comment">#训练集</span></span><br><span class="line">  best.fit<span class="operator">=</span>regsubsets<span class="punctuation">(</span>popA<span class="operator">~</span>.<span class="punctuation">,</span></span><br><span class="line">                      data <span class="operator">=</span> infsel<span class="punctuation">[</span>folds<span class="operator">!=</span>j<span class="punctuation">,</span><span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">                      nvmax <span class="operator">=</span> <span class="number">31</span><span class="punctuation">)</span></span><br><span class="line">  <span class="keyword">for</span> <span class="punctuation">(</span>i <span class="keyword">in</span> <span class="number">1</span><span class="operator">:</span><span class="number">31</span><span class="punctuation">)</span> <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="comment">#测试集</span></span><br><span class="line">    pred<span class="operator">=</span>predict<span class="punctuation">(</span>best.fit<span class="punctuation">,</span>infsel<span class="punctuation">[</span>folds<span class="operator">==</span>j<span class="punctuation">,</span><span class="punctuation">]</span><span class="punctuation">,</span>id<span class="operator">=</span>i<span class="punctuation">)</span></span><br><span class="line">    cv.error<span class="punctuation">[</span>j<span class="punctuation">,</span>i<span class="punctuation">]</span><span class="operator">&lt;-</span></span><br><span class="line">      mean<span class="punctuation">(</span><span class="punctuation">(</span>infsel<span class="operator">$</span>popA<span class="punctuation">[</span>folds<span class="operator">==</span>j<span class="punctuation">]</span><span class="operator">-</span>pred<span class="punctuation">)</span><span class="operator">^</span><span class="number">2</span><span class="punctuation">)</span></span><br><span class="line">  <span class="punctuation">&#125;</span></span><br><span class="line">  </span><br><span class="line"><span class="punctuation">&#125;</span></span><br><span class="line"><span class="comment">#cv.error为10行31列的矩阵，每个元素对应着每次(行数)交叉验证中变量数量(列数)的MSE</span></span><br><span class="line"><span class="comment">#对列求平均。得到i个变量在10次迭代中平均的MSE</span></span><br><span class="line">mean.cv.errors<span class="operator">=</span>apply<span class="punctuation">(</span>cv.error<span class="punctuation">,</span> <span class="number">2</span><span class="punctuation">,</span> mean<span class="punctuation">)</span></span><br><span class="line">mean.cv.errors</span><br><span class="line">par<span class="punctuation">(</span>mfrow<span class="operator">=</span><span class="built_in">c</span><span class="punctuation">(</span><span class="number">1</span><span class="punctuation">,</span><span class="number">1</span><span class="punctuation">)</span><span class="punctuation">)</span></span><br><span class="line">plot<span class="punctuation">(</span>mean.cv.errors<span class="punctuation">,</span>type<span class="operator">=</span><span class="string">&quot;b&quot;</span><span class="punctuation">)</span></span><br><span class="line">which.min<span class="punctuation">(</span>mean.cv.errors<span class="punctuation">)</span><span class="comment">#15</span></span><br><span class="line"><span class="comment">#对全数据进行拟合</span></span><br><span class="line">regfit.best<span class="operator">=</span>regsubsets<span class="punctuation">(</span>popA<span class="operator">~</span>.<span class="punctuation">,</span>data <span class="operator">=</span> infsel<span class="punctuation">,</span>nvmax <span class="operator">=</span> <span class="number">31</span><span class="punctuation">)</span></span><br><span class="line">coef<span class="punctuation">(</span>regfit.best<span class="punctuation">,</span><span class="number">15</span><span class="punctuation">)</span></span><br></pre></td></tr></table></figure>

<p>结果如下：与验证集结果一样，均选出了15个特征。</p>
<p><img src="/2022/03/04/%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B%E9%80%89%E6%8B%A9/image-20220302164640695.png" alt="image-20220302164640695"></p>
<p><img src="/2022/03/04/%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B%E9%80%89%E6%8B%A9/image-20220302164706404.png" alt="image-20220302164706404"></p>
<h3 id="特征缩减（Shrinkage）"><a href="#特征缩减（Shrinkage）" class="headerlink" title="特征缩减（Shrinkage）"></a>特征缩减（Shrinkage）</h3><h4 id="Lasso回归"><a href="#Lasso回归" class="headerlink" title="Lasso回归"></a>Lasso回归</h4><p>lamdar无穷大的时候，要使得Bj&#x3D;0</p>
<p><img src="/2022/03/04/%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B%E9%80%89%E6%8B%A9/image-20220302170049779.png" alt="image-20220302170049779"></p>
<p>lamdar在变化的时候，使得部分变量系数会缩减为0。</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cbegin%7Bequation*%7D++%5Csum_%7Bi=1%7D%5En(Y_i-%5Csum_%7Bj=1%7D%5Ep+X_%7Bij%7D%5Cbeta_j)%5E2+++%5Clambda+%5Csum_%7Bj=1%7D%5Ep%7B%5Cbeta_j%7D%5E2++%5Cend%7Bequation*%7D" alt="[公式]"></p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">dim</span><span class="punctuation">(</span>infsel<span class="punctuation">)</span></span><br><span class="line"><span class="comment">#model.matrix在形成数据矩阵时，还能同时将分类型变量转化为数值型</span></span><br><span class="line">x<span class="operator">=</span>model.matrix<span class="punctuation">(</span>popA<span class="operator">~</span>.<span class="punctuation">,</span>infsel<span class="punctuation">)</span><span class="punctuation">[</span><span class="punctuation">,</span><span class="operator">-</span><span class="number">1</span><span class="punctuation">]</span></span><br><span class="line"><span class="built_in">dim</span><span class="punctuation">(</span>x<span class="punctuation">)</span></span><br><span class="line">y<span class="operator">=</span>infsel<span class="operator">$</span>popA</span><br><span class="line"><span class="comment">## ridge regression ##</span></span><br><span class="line">grid<span class="operator">=</span><span class="number">10</span><span class="operator">^</span>seq<span class="punctuation">(</span><span class="number">10</span><span class="punctuation">,</span><span class="operator">-</span><span class="number">2</span><span class="punctuation">,</span><span class="built_in">length</span><span class="operator">=</span><span class="number">100</span><span class="punctuation">)</span></span><br><span class="line">ridge.mod<span class="operator">=</span>glmnet<span class="punctuation">(</span>x<span class="punctuation">,</span>y<span class="punctuation">,</span>alpha<span class="operator">=</span><span class="number">0</span><span class="punctuation">,</span>lambda <span class="operator">=</span> grid<span class="punctuation">)</span></span><br><span class="line"><span class="comment">#dim(coef(ridge.mod))</span></span><br><span class="line">set.seed<span class="punctuation">(</span><span class="number">1</span><span class="punctuation">)</span></span><br><span class="line">train<span class="operator">=</span>sample<span class="punctuation">(</span><span class="number">1</span><span class="operator">:</span>nrow<span class="punctuation">(</span>x<span class="punctuation">)</span><span class="punctuation">,</span>nrow<span class="punctuation">(</span>x<span class="punctuation">)</span><span class="operator">/</span><span class="number">2</span><span class="punctuation">)</span></span><br><span class="line">test<span class="operator">=</span><span class="punctuation">(</span><span class="operator">-</span>train<span class="punctuation">)</span></span><br><span class="line">y.test<span class="operator">=</span>y<span class="punctuation">[</span>test<span class="punctuation">]</span></span><br><span class="line">cv.out<span class="operator">=</span>cv.glmnet<span class="punctuation">(</span>x<span class="punctuation">[</span>train<span class="punctuation">,</span><span class="punctuation">]</span><span class="punctuation">,</span>y<span class="punctuation">[</span>train<span class="punctuation">]</span><span class="punctuation">,</span>alpha<span class="operator">=</span><span class="number">0</span><span class="punctuation">)</span></span><br><span class="line">plot<span class="punctuation">(</span>cv.out<span class="punctuation">)</span></span><br><span class="line">bestlam<span class="operator">=</span>cv.out<span class="operator">$</span>lambda.min</span><br><span class="line">bestlam</span><br><span class="line">ridge.pred<span class="operator">=</span>predict<span class="punctuation">(</span>ridge.mod<span class="punctuation">,</span>s<span class="operator">=</span>bestlam<span class="punctuation">,</span></span><br><span class="line">                   newx<span class="operator">=</span>x<span class="punctuation">[</span>test<span class="punctuation">,</span><span class="punctuation">]</span><span class="punctuation">)</span></span><br><span class="line">mean<span class="punctuation">(</span><span class="punctuation">(</span>ridge.pred<span class="operator">-</span>y.test<span class="punctuation">)</span><span class="operator">^</span><span class="number">2</span><span class="punctuation">)</span></span><br><span class="line">out<span class="operator">=</span>glmnet<span class="punctuation">(</span>x<span class="punctuation">,</span>y<span class="punctuation">,</span>alpha <span class="operator">=</span><span class="number">0</span><span class="punctuation">)</span></span><br><span class="line">aa<span class="operator">=</span>predict<span class="punctuation">(</span>out<span class="punctuation">,</span>type<span class="operator">=</span><span class="string">&quot;coefficients&quot;</span><span class="punctuation">,</span>s<span class="operator">=</span>bestlam<span class="punctuation">)</span><span class="punctuation">[</span><span class="number">1</span><span class="operator">:</span><span class="number">32</span><span class="punctuation">,</span><span class="punctuation">]</span></span><br><span class="line">summary<span class="punctuation">(</span>aa<span class="punctuation">)</span></span><br><span class="line">bb<span class="operator">=</span>as.data.frame<span class="punctuation">(</span>aa<span class="punctuation">)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## lasso regression ##</span></span><br><span class="line">lasso.mod<span class="operator">=</span>glmnet<span class="punctuation">(</span>x<span class="punctuation">[</span>train<span class="punctuation">,</span><span class="punctuation">]</span><span class="punctuation">,</span>y<span class="punctuation">[</span>train<span class="punctuation">]</span><span class="punctuation">,</span>alpha <span class="operator">=</span> <span class="number">1</span><span class="punctuation">,</span></span><br><span class="line">                   lambda <span class="operator">=</span> grid<span class="punctuation">)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">set.seed<span class="punctuation">(</span><span class="number">1</span><span class="punctuation">)</span></span><br><span class="line">cv.out<span class="operator">=</span>cv.glmnet<span class="punctuation">(</span>x<span class="punctuation">[</span>train<span class="punctuation">,</span><span class="punctuation">]</span><span class="punctuation">,</span>y<span class="punctuation">[</span>train<span class="punctuation">]</span><span class="punctuation">,</span>alpha<span class="operator">=</span><span class="number">1</span><span class="punctuation">)</span></span><br><span class="line">plot<span class="punctuation">(</span>cv.out<span class="punctuation">)</span></span><br><span class="line">bestlam<span class="operator">=</span>cv.out<span class="operator">$</span>lambda.min</span><br><span class="line">bestlam</span><br><span class="line">lasso.pred<span class="operator">=</span>predict<span class="punctuation">(</span>lasso.mod<span class="punctuation">,</span>s<span class="operator">=</span>bestlam<span class="punctuation">,</span></span><br><span class="line">                   newx<span class="operator">=</span>x<span class="punctuation">[</span>test<span class="punctuation">,</span><span class="punctuation">]</span><span class="punctuation">)</span></span><br><span class="line">mean<span class="punctuation">(</span><span class="punctuation">(</span>lasso.pred<span class="operator">-</span>y.test<span class="punctuation">)</span><span class="operator">^</span><span class="number">2</span><span class="punctuation">)</span></span><br><span class="line">out<span class="operator">=</span>glmnet<span class="punctuation">(</span>x<span class="punctuation">,</span>y<span class="punctuation">,</span>alpha <span class="operator">=</span><span class="number">1</span><span class="punctuation">)</span></span><br><span class="line">lasso.coef<span class="operator">=</span>predict<span class="punctuation">(</span>out<span class="punctuation">,</span>type<span class="operator">=</span><span class="string">&quot;coefficients&quot;</span><span class="punctuation">,</span>s<span class="operator">=</span>bestlam<span class="punctuation">)</span><span class="punctuation">[</span><span class="number">1</span><span class="operator">:</span><span class="number">32</span><span class="punctuation">,</span><span class="punctuation">]</span></span><br><span class="line">lasso.coef<span class="punctuation">[</span>lasso.coef<span class="operator">!=</span><span class="number">0</span><span class="punctuation">]</span></span><br></pre></td></tr></table></figure>

<h4 id="Ridge回归"><a href="#Ridge回归" class="headerlink" title="Ridge回归"></a>Ridge回归</h4><p>不适合稀疏性数据</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cbegin%7Bequation*%7D++%5Csum_%7Bi=1%7D%5En(Y_i-%5Csum_%7Bj=1%7D%5Ep+X_%7Bij%7D%5Cbeta_j)%5E2+++%5Clambda+%5Csum_%7Bj=1%7D%5Ep%7C%5Cbeta_j%7C++%5Cend%7Bequation*%7D" alt="[公式]"></p>
<p>Ridge 和 LASSO最大的区别在于，<strong>当 <img src="https://www.zhihu.com/equation?tex=%5Clambda" alt="[公式]"> 变得很大时，LASSO 回归中某些参数（也就是 <img src="https://www.zhihu.com/equation?tex=%5Cbeta" alt="[公式]"> )可以会变为0.</strong></p>
<h4 id="练习-1"><a href="#练习-1" class="headerlink" title="练习"></a>练习</h4><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">########## Ridge Regression and the Lasso #######</span></span><br><span class="line"><span class="built_in">dim</span><span class="punctuation">(</span>infsel<span class="punctuation">)</span></span><br><span class="line">x<span class="operator">=</span>model.matrix<span class="punctuation">(</span>popA<span class="operator">~</span>.<span class="punctuation">,</span>infsel<span class="punctuation">)</span><span class="punctuation">[</span><span class="punctuation">,</span><span class="operator">-</span><span class="number">1</span><span class="punctuation">]</span></span><br><span class="line"><span class="built_in">dim</span><span class="punctuation">(</span>x<span class="punctuation">)</span></span><br><span class="line">y<span class="operator">=</span>infsel<span class="operator">$</span>popA</span><br><span class="line"><span class="comment">## 01 ridge regression ##</span></span><br><span class="line">grid<span class="operator">=</span><span class="number">10</span><span class="operator">^</span>seq<span class="punctuation">(</span><span class="number">10</span><span class="punctuation">,</span><span class="operator">-</span><span class="number">2</span><span class="punctuation">,</span><span class="built_in">length</span><span class="operator">=</span><span class="number">100</span><span class="punctuation">)</span></span><br><span class="line"><span class="comment">#全模型的ridge回归</span></span><br><span class="line">ridge.mod<span class="operator">=</span>glmnet<span class="punctuation">(</span>x<span class="punctuation">,</span>y<span class="punctuation">,</span>alpha<span class="operator">=</span><span class="number">0</span><span class="punctuation">,</span>lambda <span class="operator">=</span> grid<span class="punctuation">)</span></span><br><span class="line"><span class="comment">#dim(coef(ridge.mod))</span></span><br><span class="line"><span class="comment">#在训练集和测试集下找到最好的lambda</span></span><br><span class="line">set.seed<span class="punctuation">(</span><span class="number">1</span><span class="punctuation">)</span></span><br><span class="line">train<span class="operator">=</span>sample<span class="punctuation">(</span><span class="number">1</span><span class="operator">:</span>nrow<span class="punctuation">(</span>x<span class="punctuation">)</span><span class="punctuation">,</span>nrow<span class="punctuation">(</span>x<span class="punctuation">)</span><span class="operator">/</span><span class="number">2</span><span class="punctuation">)</span></span><br><span class="line">test<span class="operator">=</span><span class="punctuation">(</span><span class="operator">-</span>train<span class="punctuation">)</span></span><br><span class="line">y.test<span class="operator">=</span>y<span class="punctuation">[</span>test<span class="punctuation">]</span></span><br><span class="line">cv.out<span class="operator">=</span>cv.glmnet<span class="punctuation">(</span>x<span class="punctuation">[</span>train<span class="punctuation">,</span><span class="punctuation">]</span><span class="punctuation">,</span>y<span class="punctuation">[</span>train<span class="punctuation">]</span><span class="punctuation">,</span>alpha<span class="operator">=</span><span class="number">0</span><span class="punctuation">)</span></span><br><span class="line">plot<span class="punctuation">(</span>cv.out<span class="punctuation">)</span></span><br><span class="line">bestlam<span class="operator">=</span>cv.out<span class="operator">$</span>lambda.min</span><br><span class="line">bestlam</span><br><span class="line">ridge.pred<span class="operator">=</span>predict<span class="punctuation">(</span>ridge.mod<span class="punctuation">,</span>s<span class="operator">=</span>bestlam<span class="punctuation">,</span></span><br><span class="line">                   newx<span class="operator">=</span>x<span class="punctuation">[</span>test<span class="punctuation">,</span><span class="punctuation">]</span><span class="punctuation">)</span></span><br><span class="line">mean<span class="punctuation">(</span><span class="punctuation">(</span>ridge.pred<span class="operator">-</span>y.test<span class="punctuation">)</span><span class="operator">^</span><span class="number">2</span><span class="punctuation">)</span></span><br><span class="line">out<span class="operator">=</span>glmnet<span class="punctuation">(</span>x<span class="punctuation">,</span>y<span class="punctuation">,</span>alpha <span class="operator">=</span><span class="number">0</span><span class="punctuation">)</span></span><br><span class="line">aa<span class="operator">=</span>predict<span class="punctuation">(</span>out<span class="punctuation">,</span>type<span class="operator">=</span><span class="string">&quot;coefficients&quot;</span><span class="punctuation">,</span>s<span class="operator">=</span>bestlam<span class="punctuation">)</span><span class="punctuation">[</span><span class="number">1</span><span class="operator">:</span><span class="number">32</span><span class="punctuation">,</span><span class="punctuation">]</span></span><br><span class="line">summary<span class="punctuation">(</span>aa<span class="punctuation">)</span></span><br><span class="line">bb<span class="operator">=</span>as.data.frame<span class="punctuation">(</span>aa<span class="punctuation">)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## lasso regression ##</span></span><br><span class="line">lasso.mod<span class="operator">=</span>glmnet<span class="punctuation">(</span>x<span class="punctuation">[</span>train<span class="punctuation">,</span><span class="punctuation">]</span><span class="punctuation">,</span>y<span class="punctuation">[</span>train<span class="punctuation">]</span><span class="punctuation">,</span>alpha <span class="operator">=</span> <span class="number">1</span><span class="punctuation">,</span></span><br><span class="line">                   lambda <span class="operator">=</span> grid<span class="punctuation">)</span></span><br><span class="line">set.seed<span class="punctuation">(</span><span class="number">1</span><span class="punctuation">)</span></span><br><span class="line">cv.out<span class="operator">=</span>cv.glmnet<span class="punctuation">(</span>x<span class="punctuation">[</span>train<span class="punctuation">,</span><span class="punctuation">]</span><span class="punctuation">,</span>y<span class="punctuation">[</span>train<span class="punctuation">]</span><span class="punctuation">,</span>alpha<span class="operator">=</span><span class="number">1</span><span class="punctuation">)</span></span><br><span class="line">plot<span class="punctuation">(</span>cv.out<span class="punctuation">)</span></span><br><span class="line">bestlam<span class="operator">=</span>cv.out<span class="operator">$</span>lambda.min</span><br><span class="line">bestlam</span><br><span class="line">lasso.pred<span class="operator">=</span>predict<span class="punctuation">(</span>lasso.mod<span class="punctuation">,</span>s<span class="operator">=</span>bestlam<span class="punctuation">,</span></span><br><span class="line">                   newx<span class="operator">=</span>x<span class="punctuation">[</span>test<span class="punctuation">,</span><span class="punctuation">]</span><span class="punctuation">)</span></span><br><span class="line">mean<span class="punctuation">(</span><span class="punctuation">(</span>lasso.pred<span class="operator">-</span>y.test<span class="punctuation">)</span><span class="operator">^</span><span class="number">2</span><span class="punctuation">)</span></span><br><span class="line">out<span class="operator">=</span>glmnet<span class="punctuation">(</span>x<span class="punctuation">,</span>y<span class="punctuation">,</span>alpha <span class="operator">=</span><span class="number">1</span><span class="punctuation">)</span></span><br><span class="line">lasso.coef<span class="operator">=</span>predict<span class="punctuation">(</span>out<span class="punctuation">,</span>type<span class="operator">=</span><span class="string">&quot;coefficients&quot;</span><span class="punctuation">,</span>s<span class="operator">=</span>bestlam<span class="punctuation">)</span><span class="punctuation">[</span><span class="number">1</span><span class="operator">:</span><span class="number">32</span><span class="punctuation">,</span><span class="punctuation">]</span></span><br><span class="line"><span class="comment">#lasso回归可以进行变量数量的选择</span></span><br><span class="line">lasso.coef<span class="punctuation">[</span>lasso.coef<span class="operator">!=</span><span class="number">0</span><span class="punctuation">]</span></span><br></pre></td></tr></table></figure>

<p>lasso图：</p>
<p><img src="/2022/03/04/%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B%E9%80%89%E6%8B%A9/image-20220302210406180.png" alt="image-20220302210406180"></p>
<p>Ridge图：</p>
<p><img src="/2022/03/04/%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B%E9%80%89%E6%8B%A9/image-20220302210444060.png" alt="image-20220302210444060"></p>
<h3 id="Dimension-Reduction"><a href="#Dimension-Reduction" class="headerlink" title="Dimension Reduction"></a>Dimension Reduction</h3><h4 id="Principal-Components-Regression-Approach"><a href="#Principal-Components-Regression-Approach" class="headerlink" title="Principal Components Regression Approach"></a>Principal Components Regression Approach</h4><p>核心思想：用少量的主成分解释数据中大部分变化。</p>
<p>下图中第一主成分定义了尽可能接近数据的直线。</p>
<p><img src="/2022/03/04/%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B%E9%80%89%E6%8B%A9/image-20220302202059200.png" alt="image-20220302202059200"></p>
<p>缺点：因为其不执行任何类型的变量选择以及不会产生直接的系数估计，因此最终生成的模型难以进行解释。</p>
<h4 id="Partial-Least-Squares"><a href="#Partial-Least-Squares" class="headerlink" title="Partial Least Squares"></a>Partial Least Squares</h4><h4 id="练习-2"><a href="#练习-2" class="headerlink" title="练习"></a>练习</h4><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">########## Principal components Regression #########</span></span><br><span class="line"><span class="comment">#install.packages(&#x27;pls&#x27;)</span></span><br><span class="line">library<span class="punctuation">(</span>pls<span class="punctuation">)</span></span><br><span class="line">set.seed<span class="punctuation">(</span><span class="number">2</span><span class="punctuation">)</span></span><br><span class="line">pcr.fit<span class="operator">=</span>pcr<span class="punctuation">(</span>popA<span class="operator">~</span>.<span class="punctuation">,</span>data <span class="operator">=</span> infsel<span class="punctuation">,</span>scale<span class="operator">=</span><span class="literal">TRUE</span><span class="punctuation">,</span></span><br><span class="line">            validation<span class="operator">=</span><span class="string">&#x27;CV&#x27;</span><span class="punctuation">)</span></span><br><span class="line">summary<span class="punctuation">(</span>pcr.fit<span class="punctuation">)</span></span><br><span class="line">validationplot<span class="punctuation">(</span>pcr.fit<span class="punctuation">,</span>val.type <span class="operator">=</span> <span class="string">&#x27;MSEP&#x27;</span><span class="punctuation">)</span></span><br><span class="line"><span class="comment">#使用测试集与训练集找到合适的特征数</span></span><br><span class="line">set.seed<span class="punctuation">(</span><span class="number">1</span><span class="punctuation">)</span></span><br><span class="line">pcr.fit<span class="operator">=</span>pcr<span class="punctuation">(</span>popA<span class="operator">~</span>.<span class="punctuation">,</span>data <span class="operator">=</span> infsel<span class="punctuation">,</span>scale<span class="operator">=</span><span class="literal">TRUE</span><span class="punctuation">,</span>subset<span class="operator">=</span>train<span class="punctuation">,</span></span><br><span class="line">            validation<span class="operator">=</span><span class="string">&#x27;CV&#x27;</span><span class="punctuation">)</span></span><br><span class="line">validationplot<span class="punctuation">(</span>pcr.fit<span class="punctuation">,</span>val.type <span class="operator">=</span> <span class="string">&#x27;MSEP&#x27;</span><span class="punctuation">)</span><span class="comment">#13</span></span><br><span class="line">pcr.pred<span class="operator">=</span>predict<span class="punctuation">(</span>pcr.fit<span class="punctuation">,</span>x<span class="punctuation">[</span>test<span class="punctuation">,</span><span class="punctuation">]</span><span class="punctuation">,</span>ncomp<span class="operator">=</span><span class="number">13</span><span class="punctuation">)</span></span><br><span class="line">mean<span class="punctuation">(</span><span class="punctuation">(</span>pcr.pred<span class="operator">-</span>y.test<span class="punctuation">)</span><span class="operator">^</span><span class="number">2</span><span class="punctuation">)</span></span><br><span class="line"><span class="comment">#使用全数据集</span></span><br><span class="line">pcr.fit<span class="operator">=</span>pcr<span class="punctuation">(</span>y<span class="operator">~</span>x<span class="punctuation">,</span>scale<span class="operator">=</span><span class="literal">TRUE</span><span class="punctuation">,</span>ncomp<span class="operator">=</span><span class="number">13</span><span class="punctuation">)</span></span><br><span class="line">summary<span class="punctuation">(</span>pcr.fit<span class="punctuation">)</span></span><br></pre></td></tr></table></figure>

<p><img src="/2022/03/04/%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B%E9%80%89%E6%8B%A9/image-20220302202917594.png" alt="image-20220302202917594"></p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><h3 id="YouTube视频"><a href="#YouTube视频" class="headerlink" title="YouTube视频"></a>YouTube视频</h3><p><a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=ctMCiL1Y4JU&amp;list=PLgy0wB3EG2h2Vizbtv1oIbfqK4JuBFPOn&amp;index=4">https://www.youtube.com/watch?v=ctMCiL1Y4JU&amp;list=PLgy0wB3EG2h2Vizbtv1oIbfqK4JuBFPOn&amp;index=4</a></p>
<p><a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=tY9VH-EnSvM&amp;list=PL3JwN3Ix6VdLz24QMQFcsUMe5eSkCR8M_&amp;index=12">https://www.youtube.com/watch?v=tY9VH-EnSvM&amp;list=PL3JwN3Ix6VdLz24QMQFcsUMe5eSkCR8M_&amp;index=12</a></p>
<p><a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=H45NWCzIDkY">https://www.youtube.com/watch?v=H45NWCzIDkY</a></p>
<h3 id="网站"><a href="#网站" class="headerlink" title="网站"></a><strong>网站</strong></h3><p><a target="_blank" rel="noopener" href="https://www.statlearning.com/resources-second-edition">https://www.statlearning.com/resources-second-edition</a></p>
<p><a target="_blank" rel="noopener" href="http://r-statistics.co/Outlier-Treatment-With-R.html">http://r-statistics.co/Outlier-Treatment-With-R.html</a></p>
<p><a target="_blank" rel="noopener" href="https://online.stat.psu.edu/stat508/lesson/7/7.1">https://online.stat.psu.edu/stat508/lesson/7/7.1</a></p>
<p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/wuliytTaotao/p/10837533.html">https://www.cnblogs.com/wuliytTaotao/p/10837533.html</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/289014877">https://zhuanlan.zhihu.com/p/289014877</a></p>
<h3 id="书籍"><a href="#书籍" class="headerlink" title="** 书籍**"></a>** 书籍**</h3><p>《An Introduction to Statistical Learning with Applications in R》</p>
<ul>
<li><strong>作者：</strong></li>
</ul>
<p><img src="/2022/03/04/%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B%E9%80%89%E6%8B%A9/image-20220302204418419.png" alt="image-20220302204418419"></p>
<h3 id="练习数据"><a href="#练习数据" class="headerlink" title="练习数据"></a>练习数据</h3><p><img src="/2022/03/04/%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B%E9%80%89%E6%8B%A9/image-20220302204858268.png" alt="image-20220302204858268"></p>
</div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">xqchen</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://xqchen723.github.io/2022/03/04/回归模型选择/">https://xqchen723.github.io/2022/03/04/回归模型选择/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://xqchen723.github.io">ChenXQ の Blog</a>！</span></div></div><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E7%BB%9F%E8%AE%A1%E5%AD%A6/">统计学</a></div><nav id="pagination"><div class="prev-post pull-left"><a href="/2022/03/13/dplyr%E6%95%B4%E7%90%86/"><i class="fa fa-chevron-left">  </i><span>dplyr整理</span></a></div></nav></div></div><footer class="footer-bg" style="background-image: url(https://cdn.pixabay.com/photo/2022/03/01/11/26/the-bedouins-7041111_1280.jpg)"><div class="layout" id="footer"><div class="copyright">&copy;2013 - 2022 By xqchen</div><div class="framework-info"><span>驱动 - </span><a target="_blank" rel="noopener" href="http://hexo.io"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 - </span><a target="_blank" rel="noopener" href="https://github.com/Molunerfinn/hexo-theme-melody"><span>Melody</span></a></div><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_page_pv"><i class="fa fa-file"></i><span id="busuanzi_value_page_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="https://cdn.jsdelivr.net/npm/animejs@latest/lib/anime.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@latest/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-ui-pack@latest/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.9.0"></script><script src="/js/fancybox.js?version=1.9.0"></script><script src="/js/sidebar.js?version=1.9.0"></script><script src="/js/copy.js?version=1.9.0"></script><script src="/js/fireworks.js?version=1.9.0"></script><script src="/js/transition.js?version=1.9.0"></script><script src="/js/scroll.js?version=1.9.0"></script><script src="/js/head.js?version=1.9.0"></script><script id="ribbon" src="/js/third-party/canvas-ribbon.js" size="150" alpha="0.6" zIndex="-1" data-click="false"></script><script>if(/Android|webOS|iPhone|iPod|iPad|BlackBerry/i.test(navigator.userAgent)) {
  $('#nav').addClass('is-mobile')
  $('footer').addClass('is-mobile')
  $('#top-container').addClass('is-mobile')
}</script></body></html>